{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "fraud_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1 classifier with an umbalance target\n",
    "fraud_df1 = fraud_df[\"fraud\"].value_counts()\n",
    "fraud_df1.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 train a logistic regression\n",
    "target = fraud_df[\"fraud\"]\n",
    "features = fraud_df.drop(columns = [\"fraud\"])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958328"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98    228001\n",
      "         1.0       0.89      0.60      0.72     21999\n",
      "\n",
      "    accuracy                           0.96    250000\n",
      "   macro avg       0.93      0.80      0.85    250000\n",
      "weighted avg       0.96      0.96      0.95    250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(X_train_scaled, columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"fraud\"] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.387752</td>\n",
       "      <td>-0.157644</td>\n",
       "      <td>-0.493357</td>\n",
       "      <td>-2.727037</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.336946</td>\n",
       "      <td>-0.182112</td>\n",
       "      <td>-0.344189</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.391129</td>\n",
       "      <td>-0.003298</td>\n",
       "      <td>0.123677</td>\n",
       "      <td>-2.727037</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.393940</td>\n",
       "      <td>-0.174882</td>\n",
       "      <td>-0.265405</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>2.988854</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.158554</td>\n",
       "      <td>-0.060809</td>\n",
       "      <td>-0.545098</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749995</th>\n",
       "      <td>0.722049</td>\n",
       "      <td>-0.185729</td>\n",
       "      <td>-0.591219</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749996</th>\n",
       "      <td>-0.388972</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>1.674822</td>\n",
       "      <td>-2.727037</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>2.988854</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749997</th>\n",
       "      <td>-0.119619</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>-0.441431</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749998</th>\n",
       "      <td>-0.231126</td>\n",
       "      <td>-0.047339</td>\n",
       "      <td>-0.387377</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749999</th>\n",
       "      <td>-0.035946</td>\n",
       "      <td>-0.146517</td>\n",
       "      <td>0.228680</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                -0.387752                       -0.157644   \n",
       "1                -0.336946                       -0.182112   \n",
       "2                -0.391129                       -0.003298   \n",
       "3                 1.393940                       -0.174882   \n",
       "4                -0.158554                       -0.060809   \n",
       "...                    ...                             ...   \n",
       "749995            0.722049                       -0.185729   \n",
       "749996           -0.388972                        0.795540   \n",
       "749997           -0.119619                        0.065778   \n",
       "749998           -0.231126                       -0.047339   \n",
       "749999           -0.035946                       -0.146517   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                            -0.493357        -2.727037  -0.733780   \n",
       "1                            -0.344189         0.366698  -0.733780   \n",
       "2                             0.123677        -2.727037  -0.733780   \n",
       "3                            -0.265405         0.366698  -0.733780   \n",
       "4                            -0.545098         0.366698  -0.733780   \n",
       "...                                ...              ...        ...   \n",
       "749995                       -0.591219         0.366698  -0.733780   \n",
       "749996                        1.674822        -2.727037   1.362806   \n",
       "749997                       -0.441431         0.366698   1.362806   \n",
       "749998                       -0.387377         0.366698  -0.733780   \n",
       "749999                        0.228680         0.366698  -0.733780   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0             -0.334576      0.733720    0.0  \n",
       "1             -0.334576      0.733720    0.0  \n",
       "2             -0.334576     -1.362918    0.0  \n",
       "3              2.988854      0.733720    0.0  \n",
       "4             -0.334576     -1.362918    0.0  \n",
       "...                 ...           ...    ...  \n",
       "749995        -0.334576     -1.362918    0.0  \n",
       "749996         2.988854     -1.362918    0.0  \n",
       "749997        -0.334576      0.733720    0.0  \n",
       "749998        -0.334576      0.733720    0.0  \n",
       "749999        -0.334576      0.733720    0.0  \n",
       "\n",
       "[750000 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fraud = train[train[\"fraud\"] == 1]\n",
    "no_fraud = train[train[\"fraud\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_fraud_oversampled = resample(fraud, \n",
    "                                    replace=True, \n",
    "                                    n_samples = len(no_fraud),\n",
    "                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31267</th>\n",
       "      <td>-0.142257</td>\n",
       "      <td>-0.120339</td>\n",
       "      <td>2.212187</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497865</th>\n",
       "      <td>-0.231245</td>\n",
       "      <td>-0.183285</td>\n",
       "      <td>2.041183</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486788</th>\n",
       "      <td>-0.136357</td>\n",
       "      <td>-0.052019</td>\n",
       "      <td>0.799811</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599113</th>\n",
       "      <td>2.918996</td>\n",
       "      <td>-0.166800</td>\n",
       "      <td>-0.521302</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524682</th>\n",
       "      <td>0.196096</td>\n",
       "      <td>-0.125161</td>\n",
       "      <td>1.955226</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749995</th>\n",
       "      <td>0.722049</td>\n",
       "      <td>-0.185729</td>\n",
       "      <td>-0.591219</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749996</th>\n",
       "      <td>-0.388972</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>1.674822</td>\n",
       "      <td>-2.727037</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>2.988854</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749997</th>\n",
       "      <td>-0.119619</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>-0.441431</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749998</th>\n",
       "      <td>-0.231126</td>\n",
       "      <td>-0.047339</td>\n",
       "      <td>-0.387377</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749999</th>\n",
       "      <td>-0.035946</td>\n",
       "      <td>-0.146517</td>\n",
       "      <td>0.228680</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369192 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "31267            -0.142257                       -0.120339   \n",
       "497865           -0.231245                       -0.183285   \n",
       "486788           -0.136357                       -0.052019   \n",
       "599113            2.918996                       -0.166800   \n",
       "524682            0.196096                       -0.125161   \n",
       "...                    ...                             ...   \n",
       "749995            0.722049                       -0.185729   \n",
       "749996           -0.388972                        0.795540   \n",
       "749997           -0.119619                        0.065778   \n",
       "749998           -0.231126                       -0.047339   \n",
       "749999           -0.035946                       -0.146517   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "31267                         2.212187         0.366698  -0.733780   \n",
       "497865                        2.041183         0.366698   1.362806   \n",
       "486788                        0.799811         0.366698  -0.733780   \n",
       "599113                       -0.521302         0.366698  -0.733780   \n",
       "524682                        1.955226         0.366698   1.362806   \n",
       "...                                ...              ...        ...   \n",
       "749995                       -0.591219         0.366698  -0.733780   \n",
       "749996                        1.674822        -2.727037   1.362806   \n",
       "749997                       -0.441431         0.366698   1.362806   \n",
       "749998                       -0.387377         0.366698  -0.733780   \n",
       "749999                        0.228680         0.366698  -0.733780   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "31267         -0.334576      0.733720    1.0  \n",
       "497865        -0.334576      0.733720    1.0  \n",
       "486788        -0.334576      0.733720    1.0  \n",
       "599113        -0.334576      0.733720    1.0  \n",
       "524682        -0.334576      0.733720    1.0  \n",
       "...                 ...           ...    ...  \n",
       "749995        -0.334576     -1.362918    0.0  \n",
       "749996         2.988854     -1.362918    0.0  \n",
       "749997        -0.334576      0.733720    0.0  \n",
       "749998        -0.334576      0.733720    0.0  \n",
       "749999        -0.334576      0.733720    0.0  \n",
       "\n",
       "[1369192 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_over = pd.concat([yes_fraud_oversampled, no_fraud])\n",
    "fraud_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAG5CAYAAABiGltHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA00UlEQVR4nO3df1BV94H//9cNyC2ycEokcL3KBvtjGS0mbbGDaFvcGsAsaH/s1rQkd8PUUlOMlIJjQjOzte4GjEW01cQmblpTY0r/sHQ6YyQQ22qoooTIFtQk3UYjBq6Y9nqv+iWAeL5/5MOZvWJQTCLK+/mYuTPhvF/c8z53cuDl+YXLtm1bAAAABrplrCcAAAAwVihCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjRY71BG50Fy9eVFdXl2JjY+VyucZ6OgAA4CrYtq2zZ8/K6/Xqllve+7gPRegKurq6lJycPNbTAAAA16Czs1NTp059z3GK0BXExsZKeveDjIuLG+PZAACAqxEKhZScnOz8Hn8vFKErGDodFhcXRxECAOAmc6XLWrhYGgAAGIsiBAAAjDWqIpSSkiKXyzXstWzZMknvXqG9atUqeb1eRUdHa968eTp8+HDYe/T19Wn58uVKSEhQTEyMFi1apJMnT4ZlAoGAfD6fLMuSZVny+Xw6c+ZMWObEiRNauHChYmJilJCQoJKSEvX394dl2tvblZWVpejoaE2ZMkWrV6+Wbduj2WQAADCOjaoItbS0qLu723k1NjZKkr7+9a9LktauXauamhpt2rRJLS0t8ng8ys7O1tmzZ533KC0tVV1dnWpra9XU1KRz584pPz9fg4ODTqagoEBtbW2qr69XfX292tra5PP5nPHBwUHl5eXp/PnzampqUm1trXbs2KHy8nInEwqFlJ2dLa/Xq5aWFm3cuFHV1dWqqam5tk8KAACMP/b78L3vfc/++Mc/bl+8eNG+ePGi7fF47DVr1jjj77zzjm1Zlv2zn/3Mtm3bPnPmjD1hwgS7trbWybz11lv2LbfcYtfX19u2bdtHjhyxJdnNzc1OZv/+/bYk+9VXX7Vt27aff/55+5ZbbrHfeustJ/OrX/3KdrvddjAYtG3btp944gnbsiz7nXfecTJVVVW21+u1L168eNXbGAwGbUnO+wIAgBvf1f7+vuZrhPr7+/Xss8/qW9/6llwul44dOya/36+cnBwn43a7lZWVpX379kmSWltbNTAwEJbxer1KS0tzMvv375dlWcrIyHAys2fPlmVZYZm0tDR5vV4nk5ubq76+PrW2tjqZrKwsud3usExXV5eOHz9+rZsNAADGkWsuQr/97W915swZFRYWSpL8fr8kKSkpKSyXlJTkjPn9fkVFRSk+Pn7ETGJi4rD1JSYmhmUuXU98fLyioqJGzAx9PZS5nL6+PoVCobAXAAAYn665CD399NO6++67w47KSMPv17dt+4r38F+auVz+g8jY/+9C6ZHmU1VV5VykbVkWT5UGAGAcu6Yi9Oabb+rFF1/Ut7/9bWeZx+ORNPxoS09Pj3MkxuPxqL+/X4FAYMTMqVOnhq3z9OnTYZlL1xMIBDQwMDBipqenR9Lwo1b/V0VFhYLBoPPq7Ox8zywAALi5XVMR+sUvfqHExETl5eU5y6ZNmyaPx+PcSSa9ex3Rnj17NGfOHElSenq6JkyYEJbp7u5WR0eHk8nMzFQwGNTBgwedzIEDBxQMBsMyHR0d6u7udjINDQ1yu91KT093Mnv37g27pb6hoUFer1cpKSnvuW1ut9t5ijRPkwYAYJwb7VXYg4OD9j/+4z/aDz300LCxNWvW2JZl2b/5zW/s9vZ2+5vf/KY9efJkOxQKOZkHHnjAnjp1qv3iiy/ar7zyiv2lL33JvvPOO+0LFy44mQULFth33HGHvX//fnv//v32zJkz7fz8fGf8woULdlpamj1//nz7lVdesV988UV76tSp9oMPPuhkzpw5YyclJdnf/OY37fb2dvs3v/mNHRcXZ1dXV49qe7lrDACAm8/V/v4edRF64YUXbEn2a6+9Nmzs4sWL9g9/+EPb4/HYbrfb/uIXv2i3t7eHZXp7e+0HH3zQvvXWW+3o6Gg7Pz/fPnHiRFjmb3/7m33vvffasbGxdmxsrH3vvffagUAgLPPmm2/aeXl5dnR0tH3rrbfaDz74YNit8rZt23/+85/tL3zhC7bb7bY9Ho+9atWqUd06b9sUIQAAbkZX+/vbZds8ankkoVBIlmUpGAxymgwAgJvE1f7+5m+NAQAAY1GEAACAsSLHegK4caU8vHOsp4Dr6PiavCuHMG6wf5uF/fu9cUQIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYCyKEAAAMBZFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFijLkJvvfWW7rvvPk2aNEkTJ07Upz/9abW2tjrjtm1r1apV8nq9io6O1rx583T48OGw9+jr69Py5cuVkJCgmJgYLVq0SCdPngzLBAIB+Xw+WZYly7Lk8/l05syZsMyJEye0cOFCxcTEKCEhQSUlJerv7w/LtLe3KysrS9HR0ZoyZYpWr14t27ZHu9kAAGAcGlURCgQCmjt3riZMmKBdu3bpyJEjWrdunT760Y86mbVr16qmpkabNm1SS0uLPB6PsrOzdfbsWSdTWlqquro61dbWqqmpSefOnVN+fr4GBwedTEFBgdra2lRfX6/6+nq1tbXJ5/M544ODg8rLy9P58+fV1NSk2tpa7dixQ+Xl5U4mFAopOztbXq9XLS0t2rhxo6qrq1VTU3MtnxUAABhnXPYoDo88/PDD+tOf/qSXXnrpsuO2bcvr9aq0tFQPPfSQpHeP/iQlJemxxx7T0qVLFQwGddttt2nbtm265557JEldXV1KTk7W888/r9zcXB09elQzZsxQc3OzMjIyJEnNzc3KzMzUq6++qtTUVO3atUv5+fnq7OyU1+uVJNXW1qqwsFA9PT2Ki4vT5s2bVVFRoVOnTsntdkuS1qxZo40bN+rkyZNyuVxX3OZQKCTLshQMBhUXF3e1H9W4kPLwzrGeAq6j42vyxnoKuI7Yv81i4v59tb+/R3VE6He/+51mzZqlr3/960pMTNRnPvMZbdmyxRk/duyY/H6/cnJynGVut1tZWVnat2+fJKm1tVUDAwNhGa/Xq7S0NCezf/9+WZbllCBJmj17tizLCsukpaU5JUiScnNz1dfX55yq279/v7KyspwSNJTp6urS8ePHL7uNfX19CoVCYS8AADA+jaoIvfHGG9q8ebM++clP6oUXXtADDzygkpIS/fKXv5Qk+f1+SVJSUlLY9yUlJTljfr9fUVFRio+PHzGTmJg4bP2JiYlhmUvXEx8fr6ioqBEzQ18PZS5VVVXlXJdkWZaSk5Ov8KkAAICb1aiK0MWLF/XZz35WlZWV+sxnPqOlS5eqqKhImzdvDstdesrJtu0rnoa6NHO5/AeRGToT+F7zqaioUDAYdF6dnZ0jzhsAANy8RlWEJk+erBkzZoQtmz59uk6cOCFJ8ng8koYfbenp6XGOxHg8HvX39ysQCIyYOXXq1LD1nz59Oixz6XoCgYAGBgZGzPT09EgaftRqiNvtVlxcXNgLAACMT6MqQnPnztVrr70Wtuz111/X7bffLkmaNm2aPB6PGhsbnfH+/n7t2bNHc+bMkSSlp6drwoQJYZnu7m51dHQ4mczMTAWDQR08eNDJHDhwQMFgMCzT0dGh7u5uJ9PQ0CC326309HQns3fv3rBb6hsaGuT1epWSkjKaTQcAAOPQqIrQ97//fTU3N6uyslL/+7//q+eee05PPfWUli1bJund002lpaWqrKxUXV2dOjo6VFhYqIkTJ6qgoECSZFmWlixZovLycu3evVuHDh3Sfffdp5kzZ+quu+6S9O5RpgULFqioqEjNzc1qbm5WUVGR8vPzlZqaKknKycnRjBkz5PP5dOjQIe3evVsrVqxQUVGRcxSnoKBAbrdbhYWF6ujoUF1dnSorK1VWVnZVd4wBAIDxLXI04c997nOqq6tTRUWFVq9erWnTpmnDhg269957nczKlSvV29ur4uJiBQIBZWRkqKGhQbGxsU5m/fr1ioyM1OLFi9Xb26v58+dr69atioiIcDLbt29XSUmJc3fZokWLtGnTJmc8IiJCO3fuVHFxsebOnavo6GgVFBSourrayViWpcbGRi1btkyzZs1SfHy8ysrKVFZWNvpPCgAAjDujeo6QiXiOEExh4nNGTMb+bRYT9+8P5TlCAAAA4wlFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYCyKEAAAMBZFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGCsURWhVatWyeVyhb08Ho8zbtu2Vq1aJa/Xq+joaM2bN0+HDx8Oe4++vj4tX75cCQkJiomJ0aJFi3Ty5MmwTCAQkM/nk2VZsixLPp9PZ86cCcucOHFCCxcuVExMjBISElRSUqL+/v6wTHt7u7KyshQdHa0pU6Zo9erVsm17NJsMAADGsVEfEfrUpz6l7u5u59Xe3u6MrV27VjU1Ndq0aZNaWlrk8XiUnZ2ts2fPOpnS0lLV1dWptrZWTU1NOnfunPLz8zU4OOhkCgoK1NbWpvr6etXX16utrU0+n88ZHxwcVF5ens6fP6+mpibV1tZqx44dKi8vdzKhUEjZ2dnyer1qaWnRxo0bVV1drZqamlF/SAAAYHyKHPU3REaGHQUaYtu2NmzYoEceeURf+9rXJEnPPPOMkpKS9Nxzz2np0qUKBoN6+umntW3bNt11112SpGeffVbJycl68cUXlZubq6NHj6q+vl7Nzc3KyMiQJG3ZskWZmZl67bXXlJqaqoaGBh05ckSdnZ3yer2SpHXr1qmwsFCPPvqo4uLitH37dr3zzjvaunWr3G630tLS9Prrr6umpkZlZWVyuVzX/KEBAIDxYdRHhP7yl7/I6/Vq2rRp+sY3vqE33nhDknTs2DH5/X7l5OQ4WbfbraysLO3bt0+S1NraqoGBgbCM1+tVWlqak9m/f78sy3JKkCTNnj1blmWFZdLS0pwSJEm5ubnq6+tTa2urk8nKypLb7Q7LdHV16fjx46PdbAAAMA6NqghlZGTol7/8pV544QVt2bJFfr9fc+bM0d/+9jf5/X5JUlJSUtj3JCUlOWN+v19RUVGKj48fMZOYmDhs3YmJiWGZS9cTHx+vqKioETNDXw9lLqevr0+hUCjsBQAAxqdRnRq7++67nf+eOXOmMjMz9fGPf1zPPPOMZs+eLUnDTjnZtn3F01CXZi6X/yAyQxdKjzSfqqoq/ehHPxpxvgAAYHx4X7fPx8TEaObMmfrLX/7iXDd06dGWnp4e50iMx+NRf3+/AoHAiJlTp04NW9fp06fDMpeuJxAIaGBgYMRMT0+PpOFHrf6viooKBYNB59XZ2TnyhwAAAG5a76sI9fX16ejRo5o8ebKmTZsmj8ejxsZGZ7y/v1979uzRnDlzJEnp6emaMGFCWKa7u1sdHR1OJjMzU8FgUAcPHnQyBw4cUDAYDMt0dHSou7vbyTQ0NMjtdis9Pd3J7N27N+yW+oaGBnm9XqWkpLznNrndbsXFxYW9AADA+DSqIrRixQrt2bNHx44d04EDB/Rv//ZvCoVCuv/+++VyuVRaWqrKykrV1dWpo6NDhYWFmjhxogoKCiRJlmVpyZIlKi8v1+7du3Xo0CHdd999mjlzpnMX2fTp07VgwQIVFRWpublZzc3NKioqUn5+vlJTUyVJOTk5mjFjhnw+nw4dOqTdu3drxYoVKioqcopLQUGB3G63CgsL1dHRobq6OlVWVnLHGAAAcIzqGqGTJ0/qm9/8pt5++23ddtttmj17tpqbm3X77bdLklauXKne3l4VFxcrEAgoIyNDDQ0Nio2Ndd5j/fr1ioyM1OLFi9Xb26v58+dr69atioiIcDLbt29XSUmJc3fZokWLtGnTJmc8IiJCO3fuVHFxsebOnavo6GgVFBSourrayViWpcbGRi1btkyzZs1SfHy8ysrKVFZWdm2fFAAAGHdcNo9aHlEoFJJlWQoGg8adJkt5eOdYTwHX0fE1eWM9BVxH7N9mMXH/vtrf3/ytMQAAYCyKEAAAMBZFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYCyKEAAAMBZFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBY76sIVVVVyeVyqbS01Flm27ZWrVolr9er6OhozZs3T4cPHw77vr6+Pi1fvlwJCQmKiYnRokWLdPLkybBMIBCQz+eTZVmyLEs+n09nzpwJy5w4cUILFy5UTEyMEhISVFJSov7+/rBMe3u7srKyFB0drSlTpmj16tWybfv9bDYAABgnrrkItbS06KmnntIdd9wRtnzt2rWqqanRpk2b1NLSIo/Ho+zsbJ09e9bJlJaWqq6uTrW1tWpqatK5c+eUn5+vwcFBJ1NQUKC2tjbV19ervr5ebW1t8vl8zvjg4KDy8vJ0/vx5NTU1qba2Vjt27FB5ebmTCYVCys7OltfrVUtLizZu3Kjq6mrV1NRc62YDAIBxJPJavuncuXO69957tWXLFv3Xf/2Xs9y2bW3YsEGPPPKIvva1r0mSnnnmGSUlJem5557T0qVLFQwG9fTTT2vbtm266667JEnPPvuskpOT9eKLLyo3N1dHjx5VfX29mpublZGRIUnasmWLMjMz9dprryk1NVUNDQ06cuSIOjs75fV6JUnr1q1TYWGhHn30UcXFxWn79u165513tHXrVrndbqWlpen1119XTU2NysrK5HK53teHBwAAbm7XdERo2bJlysvLc4rMkGPHjsnv9ysnJ8dZ5na7lZWVpX379kmSWltbNTAwEJbxer1KS0tzMvv375dlWU4JkqTZs2fLsqywTFpamlOCJCk3N1d9fX1qbW11MllZWXK73WGZrq4uHT9+/Fo2HQAAjCOjPiJUW1urV155RS0tLcPG/H6/JCkpKSlseVJSkt58800nExUVpfj4+GGZoe/3+/1KTEwc9v6JiYlhmUvXEx8fr6ioqLBMSkrKsPUMjU2bNm3YOvr6+tTX1+d8HQqFhmUAAMD4MKojQp2dnfre976nZ599Vh/5yEfeM3fpKSfbtq94GurSzOXyH0Rm6ELp95pPVVWVc4G2ZVlKTk4ecd4AAODmNaoi1Nraqp6eHqWnpysyMlKRkZHas2ePfvrTnyoyMjLsaMv/1dPT44x5PB719/crEAiMmDl16tSw9Z8+fTosc+l6AoGABgYGRsz09PRIGn7UakhFRYWCwaDz6uzsvPIHAwAAbkqjKkLz589Xe3u72tranNesWbN07733qq2tTR/72Mfk8XjU2NjofE9/f7/27NmjOXPmSJLS09M1YcKEsEx3d7c6OjqcTGZmpoLBoA4ePOhkDhw4oGAwGJbp6OhQd3e3k2loaJDb7VZ6erqT2bt3b9gt9Q0NDfJ6vcNOmQ1xu92Ki4sLewEAgPFpVNcIxcbGKi0tLWxZTEyMJk2a5CwvLS1VZWWlPvnJT+qTn/ykKisrNXHiRBUUFEiSLMvSkiVLVF5erkmTJunWW2/VihUrNHPmTOfi6+nTp2vBggUqKirSk08+KUn6zne+o/z8fKWmpkqScnJyNGPGDPl8Pv34xz/W3//+d61YsUJFRUVOeSkoKNCPfvQjFRYW6gc/+IH+8pe/qLKyUv/xH//BHWMAAODabp8fycqVK9Xb26vi4mIFAgFlZGSooaFBsbGxTmb9+vWKjIzU4sWL1dvbq/nz52vr1q2KiIhwMtu3b1dJSYlzd9miRYu0adMmZzwiIkI7d+5UcXGx5s6dq+joaBUUFKi6utrJWJalxsZGLVu2TLNmzVJ8fLzKyspUVlb2QW82AAC4CblsHrM8olAoJMuyFAwGjTtNlvLwzrGeAq6j42vyxnoKuI7Yv81i4v59tb+/+VtjAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYCyKEAAAMBZFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFijKkKbN2/WHXfcobi4OMXFxSkzM1O7du1yxm3b1qpVq+T1ehUdHa158+bp8OHDYe/R19en5cuXKyEhQTExMVq0aJFOnjwZlgkEAvL5fLIsS5Zlyefz6cyZM2GZEydOaOHChYqJiVFCQoJKSkrU398flmlvb1dWVpaio6M1ZcoUrV69WrZtj2aTAQDAODaqIjR16lStWbNGL7/8sl5++WV96Utf0pe//GWn7Kxdu1Y1NTXatGmTWlpa5PF4lJ2drbNnzzrvUVpaqrq6OtXW1qqpqUnnzp1Tfn6+BgcHnUxBQYHa2tpUX1+v+vp6tbW1yefzOeODg4PKy8vT+fPn1dTUpNraWu3YsUPl5eVOJhQKKTs7W16vVy0tLdq4caOqq6tVU1NzzR8WAAAYX1z2+zxEcuutt+rHP/6xvvWtb8nr9aq0tFQPPfSQpHeP/iQlJemxxx7T0qVLFQwGddttt2nbtm265557JEldXV1KTk7W888/r9zcXB09elQzZsxQc3OzMjIyJEnNzc3KzMzUq6++qtTUVO3atUv5+fnq7OyU1+uVJNXW1qqwsFA9PT2Ki4vT5s2bVVFRoVOnTsntdkuS1qxZo40bN+rkyZNyuVxXtX2hUEiWZSkYDCouLu79fFQ3nZSHd471FHAdHV+TN9ZTwHXE/m0WE/fvq/39fc3XCA0ODqq2tlbnz59XZmamjh07Jr/fr5ycHCfjdruVlZWlffv2SZJaW1s1MDAQlvF6vUpLS3My+/fvl2VZTgmSpNmzZ8uyrLBMWlqaU4IkKTc3V319fWptbXUyWVlZTgkaynR1den48ePvuV19fX0KhUJhLwAAMD6Nugi1t7frH/7hH+R2u/XAAw+orq5OM2bMkN/vlyQlJSWF5ZOSkpwxv9+vqKgoxcfHj5hJTEwctt7ExMSwzKXriY+PV1RU1IiZoa+HMpdTVVXlXJtkWZaSk5NH/kAAAMBNa9RFKDU1VW1tbWpubtZ3v/td3X///Tpy5IgzfukpJ9u2r3ga6tLM5fIfRGboLOBI86moqFAwGHRenZ2dI84dAADcvEZdhKKiovSJT3xCs2bNUlVVle6880795Cc/kcfjkTT8aEtPT49zJMbj8ai/v1+BQGDEzKlTp4at9/Tp02GZS9cTCAQ0MDAwYqanp0fS8KNW/5fb7Xbuiht6AQCA8el9P0fItm319fVp2rRp8ng8amxsdMb6+/u1Z88ezZkzR5KUnp6uCRMmhGW6u7vV0dHhZDIzMxUMBnXw4EEnc+DAAQWDwbBMR0eHuru7nUxDQ4PcbrfS09OdzN69e8NuqW9oaJDX61VKSsr73WwAADAOjKoI/eAHP9BLL72k48ePq729XY888oj++Mc/6t5775XL5VJpaakqKytVV1enjo4OFRYWauLEiSooKJAkWZalJUuWqLy8XLt379ahQ4d03333aebMmbrrrrskSdOnT9eCBQtUVFSk5uZmNTc3q6ioSPn5+UpNTZUk5eTkaMaMGfL5fDp06JB2796tFStWqKioyDmCU1BQILfbrcLCQnV0dKiurk6VlZUqKyu76jvGAADA+BY5mvCpU6fk8/nU3d0ty7J0xx13qL6+XtnZ2ZKklStXqre3V8XFxQoEAsrIyFBDQ4NiY2Od91i/fr0iIyO1ePFi9fb2av78+dq6dasiIiKczPbt21VSUuLcXbZo0SJt2rTJGY+IiNDOnTtVXFysuXPnKjo6WgUFBaqurnYylmWpsbFRy5Yt06xZsxQfH6+ysjKVlZVd2ycFAADGnff9HKHxjucIwRQmPmfEZOzfZjFx//7QnyMEAABws6MIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYCyKEAAAMBZFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIw1qiJUVVWlz33uc4qNjVViYqK+8pWv6LXXXgvL2LatVatWyev1Kjo6WvPmzdPhw4fDMn19fVq+fLkSEhIUExOjRYsW6eTJk2GZQCAgn88ny7JkWZZ8Pp/OnDkTljlx4oQWLlyomJgYJSQkqKSkRP39/WGZ9vZ2ZWVlKTo6WlOmTNHq1atl2/ZoNhsAAIxToypCe/bs0bJly9Tc3KzGxkZduHBBOTk5On/+vJNZu3atampqtGnTJrW0tMjj8Sg7O1tnz551MqWlpaqrq1Ntba2ampp07tw55efna3Bw0MkUFBSora1N9fX1qq+vV1tbm3w+nzM+ODiovLw8nT9/Xk1NTaqtrdWOHTtUXl7uZEKhkLKzs+X1etXS0qKNGzequrpaNTU11/RhAQCA8cVlv4/DI6dPn1ZiYqL27NmjL37xi7JtW16vV6WlpXrooYckvXv0JykpSY899piWLl2qYDCo2267Tdu2bdM999wjSerq6lJycrKef/555ebm6ujRo5oxY4aam5uVkZEhSWpublZmZqZeffVVpaamateuXcrPz1dnZ6e8Xq8kqba2VoWFherp6VFcXJw2b96siooKnTp1Sm63W5K0Zs0abdy4USdPnpTL5briNoZCIVmWpWAwqLi4uGv9qG5KKQ/vHOsp4Do6viZvrKeA64j92ywm7t9X+/v7fV0jFAwGJUm33nqrJOnYsWPy+/3KyclxMm63W1lZWdq3b58kqbW1VQMDA2EZr9ertLQ0J7N//35ZluWUIEmaPXu2LMsKy6SlpTklSJJyc3PV19en1tZWJ5OVleWUoKFMV1eXjh8//n42HQAAjAPXXIRs21ZZWZk+//nPKy0tTZLk9/slSUlJSWHZpKQkZ8zv9ysqKkrx8fEjZhITE4etMzExMSxz6Xri4+MVFRU1Ymbo66HMpfr6+hQKhcJeAABgfLrmIvTggw/qz3/+s371q18NG7v0lJNt21c8DXVp5nL5DyIzdCbwveZTVVXlXKBtWZaSk5NHnDcAALh5XVMRWr58uX73u9/pD3/4g6ZOneos93g8koYfbenp6XGOxHg8HvX39ysQCIyYOXXq1LD1nj59Oixz6XoCgYAGBgZGzPT09EgaftRqSEVFhYLBoPPq7Owc4ZMAAAA3s1EVIdu29eCDD+o3v/mNfv/732vatGlh49OmTZPH41FjY6OzrL+/X3v27NGcOXMkSenp6ZowYUJYpru7Wx0dHU4mMzNTwWBQBw8edDIHDhxQMBgMy3R0dKi7u9vJNDQ0yO12Kz093cns3bs37Jb6hoYGeb1epaSkXHYb3W634uLiwl4AAGB8GlURWrZsmZ599lk999xzio2Nld/vl9/vV29vr6R3TzeVlpaqsrJSdXV16ujoUGFhoSZOnKiCggJJkmVZWrJkicrLy7V7924dOnRI9913n2bOnKm77rpLkjR9+nQtWLBARUVFam5uVnNzs4qKipSfn6/U1FRJUk5OjmbMmCGfz6dDhw5p9+7dWrFihYqKipzyUlBQILfbrcLCQnV0dKiurk6VlZUqKyu7qjvGAADA+BY5mvDmzZslSfPmzQtb/otf/EKFhYWSpJUrV6q3t1fFxcUKBALKyMhQQ0ODYmNjnfz69esVGRmpxYsXq7e3V/Pnz9fWrVsVERHhZLZv366SkhLn7rJFixZp06ZNznhERIR27typ4uJizZ07V9HR0SooKFB1dbWTsSxLjY2NWrZsmWbNmqX4+HiVlZWprKxsNJsNAADGqff1HCET8BwhmMLE54yYjP3bLCbu39flOUIAAAA3M4oQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYCyKEAAAMBZFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYKxRF6G9e/dq4cKF8nq9crlc+u1vfxs2btu2Vq1aJa/Xq+joaM2bN0+HDx8Oy/T19Wn58uVKSEhQTEyMFi1apJMnT4ZlAoGAfD6fLMuSZVny+Xw6c+ZMWObEiRNauHChYmJilJCQoJKSEvX394dl2tvblZWVpejoaE2ZMkWrV6+Wbduj3WwAADAOjboInT9/Xnfeeac2bdp02fG1a9eqpqZGmzZtUktLizwej7Kzs3X27FknU1paqrq6OtXW1qqpqUnnzp1Tfn6+BgcHnUxBQYHa2tpUX1+v+vp6tbW1yefzOeODg4PKy8vT+fPn1dTUpNraWu3YsUPl5eVOJhQKKTs7W16vVy0tLdq4caOqq6tVU1Mz2s0GAADjUORov+Huu+/W3Xfffdkx27a1YcMGPfLII/ra174mSXrmmWeUlJSk5557TkuXLlUwGNTTTz+tbdu26a677pIkPfvss0pOTtaLL76o3NxcHT16VPX19WpublZGRoYkacuWLcrMzNRrr72m1NRUNTQ06MiRI+rs7JTX65UkrVu3ToWFhXr00UcVFxen7du365133tHWrVvldruVlpam119/XTU1NSorK5PL5bqmDw0AAIwPH+g1QseOHZPf71dOTo6zzO12KysrS/v27ZMktba2amBgICzj9XqVlpbmZPbv3y/LspwSJEmzZ8+WZVlhmbS0NKcESVJubq76+vrU2trqZLKysuR2u8MyXV1dOn78+GW3oa+vT6FQKOwFAADGpw+0CPn9fklSUlJS2PKkpCRnzO/3KyoqSvHx8SNmEhMTh71/YmJiWObS9cTHxysqKmrEzNDXQ5lLVVVVOdclWZal5OTkK284AAC4KX0od41desrJtu0rnoa6NHO5/AeRGbpQ+r3mU1FRoWAw6Lw6OztHnDcAALh5faBFyOPxSBp+tKWnp8c5EuPxeNTf369AIDBi5tSpU8Pe//Tp02GZS9cTCAQ0MDAwYqanp0fS8KNWQ9xut+Li4sJeAABgfPpAi9C0adPk8XjU2NjoLOvv79eePXs0Z84cSVJ6eromTJgQlunu7lZHR4eTyczMVDAY1MGDB53MgQMHFAwGwzIdHR3q7u52Mg0NDXK73UpPT3cye/fuDbulvqGhQV6vVykpKR/kpgMAgJvQqIvQuXPn1NbWpra2NknvXiDd1tamEydOyOVyqbS0VJWVlaqrq1NHR4cKCws1ceJEFRQUSJIsy9KSJUtUXl6u3bt369ChQ7rvvvs0c+ZM5y6y6dOna8GCBSoqKlJzc7Oam5tVVFSk/Px8paamSpJycnI0Y8YM+Xw+HTp0SLt379aKFStUVFTkHMUpKCiQ2+1WYWGhOjo6VFdXp8rKSu4YAwAAkq7h9vmXX35Z//zP/+x8XVZWJkm6//77tXXrVq1cuVK9vb0qLi5WIBBQRkaGGhoaFBsb63zP+vXrFRkZqcWLF6u3t1fz58/X1q1bFRER4WS2b9+ukpIS5+6yRYsWhT27KCIiQjt37lRxcbHmzp2r6OhoFRQUqLq62slYlqXGxkYtW7ZMs2bNUnx8vMrKypw5AwAAs7lsHrM8olAoJMuyFAwGjbteKOXhnWM9BVxHx9fkjfUUcB2xf5vFxP37an9/87fGAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYCyKEAAAMBZFCAAAGIsiBAAAjEURAgAAxqIIAQAAY1GEAACAsShCAADAWBQhAABgLIoQAAAwFkUIAAAYiyIEAACMRRECAADGoggBAABjUYQAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGMZUYSeeOIJTZs2TR/5yEeUnp6ul156aaynBAAAbgDjvgj9+te/VmlpqR555BEdOnRIX/jCF3T33XfrxIkTYz01AAAwxsZ9EaqpqdGSJUv07W9/W9OnT9eGDRuUnJyszZs3j/XUAADAGBvXRai/v1+tra3KyckJW56Tk6N9+/aN0awAAMCNInKsJ/BhevvttzU4OKikpKSw5UlJSfL7/Zf9nr6+PvX19TlfB4NBSVIoFPrwJnqDutj3/431FHAdmfj/uMnYv81i4v49tM22bY+YG9dFaIjL5Qr72rbtYcuGVFVV6Uc/+tGw5cnJyR/K3IAbhbVhrGcA4MNi8v599uxZWZb1nuPjugglJCQoIiJi2NGfnp6eYUeJhlRUVKisrMz5+uLFi/r73/+uSZMmvWd5wvgRCoWUnJyszs5OxcXFjfV0AHyA2L/NYtu2zp49K6/XO2JuXBehqKgopaenq7GxUV/96led5Y2Njfryl7982e9xu91yu91hyz760Y9+mNPEDSguLo4flMA4xf5tjpGOBA0Z10VIksrKyuTz+TRr1ixlZmbqqaee0okTJ/TAAw+M9dQAAMAYG/dF6J577tHf/vY3rV69Wt3d3UpLS9Pzzz+v22+/faynBgAAxti4L0KSVFxcrOLi4rGeBm4CbrdbP/zhD4edHgVw82P/xuW47CvdVwYAADBOjesHKgIAAIyEIgQAAIxFEQIAAMaiCAEAAGMZcdcYAMBcg4ODevvtt+VyuTRp0iRFRESM9ZRwA+GIEPD/DA4O6tSpU+rp6dHg4OBYTwfA+1RXV6e5c+dq4sSJ8nq9mjx5siZOnKi5c+fqt7/97VhPDzcIihCMxw9LYPx58skn9Y1vfEN33HGHfv3rX6upqUkvvfSSfv3rX+uOO+7QN77xDW3ZsmWsp4kbAM8RgtGefPJJlZSU6Fvf+pZyc3OVlJQk27bV09OjF154Qb/4xS+0ceNGFRUVjfVUAYzCJz7xCVVUVGjJkiWXHf/5z3+uRx99VH/961+v88xwo6EIwWj8sATGp+joaLW1tSk1NfWy46+++qo+85nPqLe39zrPDDcaTo3BaG+99ZY+//nPv+f4nDlz1NXVdR1nBOCD8KlPfUpPPfXUe45v2bJFn/rUp67jjHCj4q4xGG3oh+W6desuO84PS+DmtG7dOuXl5am+vl45OTlKSkqSy+WS3+9XY2Oj3nzzTT3//PNjPU3cADg1BqPt2bNHeXl5uv3220f8YfmFL3xhrKcKYJSOHz+uzZs3q7m5WX6/X5Lk8XiUmZmpBx54QCkpKWM7QdwQKEIwHj8sAcBcFCEAAGAsLpYGABjn/vvv15e+9KWxngZuABQhYAT8sATGJ6/Xq9tvv32sp4EbAHeNASPwer265Rb+vQCMN1VVVWM9BdwguEYIADAunTx5Ups3b9a+ffvk9/vlcrmUlJSkOXPm6Lvf/a6mTp061lPEDYAiBIygs7NTP/zhD/Xzn/98rKcCYBSampp09913Kzk52Xk0xtCfz2lsbFRnZ6d27dqluXPnjvVUMcYoQsAI/ud//kef/exn+Wv0wE3mc5/7nD7/+c9r/fr1lx3//ve/r6amJrW0tFznmeFGQxGC0X73u9+NOP7GG2+ovLycIgTcZPhbY7haXCwNo33lK1+Ry+XSSP8ecLlc13FGAD4IkydP1r59+96zCO3fv1+TJ0++zrPCjYgiBKNNnjxZjz/+uL7yla9cdrytrU3p6enXd1IA3rcVK1bogQceUGtrq7Kzs4f9+Zz//u//1oYNG8Z6mrgBUIRgtPT0dL3yyivvWYSudLQIwI2puLhYkyZN0vr16/Xkk086p7cjIiKUnp6uX/7yl1q8ePEYzxI3Aq4RgtFeeuklnT9/XgsWLLjs+Pnz5/Xyyy8rKyvrOs8MwAdlYGBAb7/9tiQpISFBEyZMGOMZ4UZCEQIAAMbikbkAAMBYFCEAAGAsihAAADAWRQgAABiLIgTgpmXbtr7zne/o1ltvlcvlUltb23Vdf2Fh4Xs+egHAzYHnCAG4adXX12vr1q364x//qI997GNKSEgY6ykBuMlQhADctP76179q8uTJmjNnzmXH+/v7FRUVdZ1nBeBmwqkxADelwsJCLV++XCdOnJDL5VJKSormzZunBx98UGVlZUpISFB2drYkqaamRjNnzlRMTIySk5NVXFysc+fOOe+1atUqffrTnw57/w0bNiglJcX5enBwUGVlZfroRz+qSZMmaeXKlTx1HBgHKEIAbko/+clPtHr1ak2dOlXd3d1qaWmRJD3zzDOKjIzUn/70Jz355JOSpFtuuUU//elP1dHRoWeeeUa///3vtXLlylGtb926dfr5z3+up59+Wk1NTfr73/+uurq6D3y7AFxfnBoDcFOyLEuxsbGKiIiQx+Nxln/iE5/Q2rVrw7KlpaXOf0+bNk3/+Z//qe9+97t64oknrnp9GzZsUEVFhf71X/9VkvSzn/1ML7zwwvvbCABjjiIEYFyZNWvWsGV/+MMfVFlZqSNHjigUCunChQt65513dP78ecXExFzxPYPBoLq7u5WZmeksi4yM1KxZszg9BtzkODUGYFy5tNi8+eab+pd/+RelpaVpx44dam1t1eOPPy7p3T/GKb176uzSQjM0BmB8owgBGNdefvllXbhwQevWrdPs2bP1T//0T+rq6grL3HbbbfL7/WFl6P8+k8iyLE2ePFnNzc3OsgsXLqi1tfVDnz+ADxdFCMC49vGPf1wXLlzQxo0b9cYbb2jbtm362c9+FpaZN2+eTp8+rbVr1+qvf/2rHn/8ce3atSss873vfU9r1qxRXV2dXn31VRUXF+vMmTPXcUsAfBgoQgDGtU9/+tOqqanRY489prS0NG3fvl1VVVVhmenTp+uJJ57Q448/rjvvvFMHDx7UihUrwjLl5eX693//dxUWFiozM1OxsbH66le/ej03BcCHwGVzpR8AADAUR4QAAICxKEIAAMBYFCEAAGAsihAAADAWRQgAABiLIgQAAIxFEQIAAMaiCAEAAGNRhAAAgLEoQgAAwFgUIQAAYCyKEAAAMNb/D9BOs3kozMppAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud_plt = fraud_over[\"fraud\"].value_counts()\n",
    "fraud_plt.plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over = fraud_over.drop(columns = [\"fraud\"])\n",
    "y_train_over = fraud_over[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    228001\n",
      "         1.0       0.58      0.95      0.72     21999\n",
      "\n",
      "    accuracy                           0.93    250000\n",
      "   macro avg       0.79      0.94      0.84    250000\n",
      "weighted avg       0.96      0.93      0.94    250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448144</th>\n",
       "      <td>0.076106</td>\n",
       "      <td>-0.185811</td>\n",
       "      <td>-0.210923</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>0.574601</td>\n",
       "      <td>-0.188048</td>\n",
       "      <td>0.271134</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95088</th>\n",
       "      <td>-0.118503</td>\n",
       "      <td>-0.187315</td>\n",
       "      <td>-0.477610</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414555</th>\n",
       "      <td>1.823591</td>\n",
       "      <td>-0.178319</td>\n",
       "      <td>-0.276073</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422759</th>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.188603</td>\n",
       "      <td>-0.576950</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>-0.304667</td>\n",
       "      <td>-0.167093</td>\n",
       "      <td>0.109102</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602619</th>\n",
       "      <td>-0.337087</td>\n",
       "      <td>-0.096948</td>\n",
       "      <td>-0.415894</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537888</th>\n",
       "      <td>0.833634</td>\n",
       "      <td>-0.182995</td>\n",
       "      <td>-0.643543</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181253</th>\n",
       "      <td>-0.349958</td>\n",
       "      <td>-0.184472</td>\n",
       "      <td>7.900497</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526136</th>\n",
       "      <td>-0.251236</td>\n",
       "      <td>-0.185161</td>\n",
       "      <td>0.085949</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65404 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "448144            0.076106                       -0.185811   \n",
       "39639             0.574601                       -0.188048   \n",
       "95088            -0.118503                       -0.187315   \n",
       "414555            1.823591                       -0.178319   \n",
       "422759           -0.011142                       -0.188603   \n",
       "...                    ...                             ...   \n",
       "6279             -0.304667                       -0.167093   \n",
       "602619           -0.337087                       -0.096948   \n",
       "537888            0.833634                       -0.182995   \n",
       "181253           -0.349958                       -0.184472   \n",
       "526136           -0.251236                       -0.185161   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "448144                       -0.210923         0.366698  -0.733780   \n",
       "39639                         0.271134         0.366698  -0.733780   \n",
       "95088                        -0.477610         0.366698   1.362806   \n",
       "414555                       -0.276073         0.366698   1.362806   \n",
       "422759                       -0.576950         0.366698  -0.733780   \n",
       "...                                ...              ...        ...   \n",
       "6279                          0.109102         0.366698  -0.733780   \n",
       "602619                       -0.415894         0.366698   1.362806   \n",
       "537888                       -0.643543         0.366698  -0.733780   \n",
       "181253                        7.900497         0.366698  -0.733780   \n",
       "526136                        0.085949         0.366698  -0.733780   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "448144        -0.334576     -1.362918    0.0  \n",
       "39639         -0.334576      0.733720    0.0  \n",
       "95088         -0.334576     -1.362918    0.0  \n",
       "414555        -0.334576     -1.362918    0.0  \n",
       "422759        -0.334576      0.733720    0.0  \n",
       "...                 ...           ...    ...  \n",
       "6279          -0.334576      0.733720    0.0  \n",
       "602619        -0.334576      0.733720    0.0  \n",
       "537888        -0.334576     -1.362918    0.0  \n",
       "181253        -0.334576     -1.362918    0.0  \n",
       "526136        -0.334576     -1.362918    0.0  \n",
       "\n",
       "[65404 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_fraud_undersampled = resample(no_fraud, \n",
    "                                    replace=False,\n",
    "                                    n_samples = len(fraud), \n",
    "                                    random_state=0)\n",
    "no_fraud_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448144</th>\n",
       "      <td>0.076106</td>\n",
       "      <td>-0.185811</td>\n",
       "      <td>-0.210923</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>0.574601</td>\n",
       "      <td>-0.188048</td>\n",
       "      <td>0.271134</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95088</th>\n",
       "      <td>-0.118503</td>\n",
       "      <td>-0.187315</td>\n",
       "      <td>-0.477610</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414555</th>\n",
       "      <td>1.823591</td>\n",
       "      <td>-0.178319</td>\n",
       "      <td>-0.276073</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422759</th>\n",
       "      <td>-0.011142</td>\n",
       "      <td>-0.188603</td>\n",
       "      <td>-0.576950</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749995</th>\n",
       "      <td>0.722049</td>\n",
       "      <td>-0.185729</td>\n",
       "      <td>-0.591219</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749996</th>\n",
       "      <td>-0.388972</td>\n",
       "      <td>0.795540</td>\n",
       "      <td>1.674822</td>\n",
       "      <td>-2.727037</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>2.988854</td>\n",
       "      <td>-1.362918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749997</th>\n",
       "      <td>-0.119619</td>\n",
       "      <td>0.065778</td>\n",
       "      <td>-0.441431</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>1.362806</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749998</th>\n",
       "      <td>-0.231126</td>\n",
       "      <td>-0.047339</td>\n",
       "      <td>-0.387377</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749999</th>\n",
       "      <td>-0.035946</td>\n",
       "      <td>-0.146517</td>\n",
       "      <td>0.228680</td>\n",
       "      <td>0.366698</td>\n",
       "      <td>-0.733780</td>\n",
       "      <td>-0.334576</td>\n",
       "      <td>0.733720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "448144            0.076106                       -0.185811   \n",
       "39639             0.574601                       -0.188048   \n",
       "95088            -0.118503                       -0.187315   \n",
       "414555            1.823591                       -0.178319   \n",
       "422759           -0.011142                       -0.188603   \n",
       "...                    ...                             ...   \n",
       "749995            0.722049                       -0.185729   \n",
       "749996           -0.388972                        0.795540   \n",
       "749997           -0.119619                        0.065778   \n",
       "749998           -0.231126                       -0.047339   \n",
       "749999           -0.035946                       -0.146517   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "448144                       -0.210923         0.366698  -0.733780   \n",
       "39639                         0.271134         0.366698  -0.733780   \n",
       "95088                        -0.477610         0.366698   1.362806   \n",
       "414555                       -0.276073         0.366698   1.362806   \n",
       "422759                       -0.576950         0.366698  -0.733780   \n",
       "...                                ...              ...        ...   \n",
       "749995                       -0.591219         0.366698  -0.733780   \n",
       "749996                        1.674822        -2.727037   1.362806   \n",
       "749997                       -0.441431         0.366698   1.362806   \n",
       "749998                       -0.387377         0.366698  -0.733780   \n",
       "749999                        0.228680         0.366698  -0.733780   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "448144        -0.334576     -1.362918    0.0  \n",
       "39639         -0.334576      0.733720    0.0  \n",
       "95088         -0.334576     -1.362918    0.0  \n",
       "414555        -0.334576     -1.362918    0.0  \n",
       "422759        -0.334576      0.733720    0.0  \n",
       "...                 ...           ...    ...  \n",
       "749995        -0.334576     -1.362918    0.0  \n",
       "749996         2.988854     -1.362918    0.0  \n",
       "749997        -0.334576      0.733720    0.0  \n",
       "749998        -0.334576      0.733720    0.0  \n",
       "749999        -0.334576      0.733720    0.0  \n",
       "\n",
       "[750000 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_over1 = pd.concat([no_fraud_undersampled, no_fraud])\n",
    "fraud_over1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_under = fraud_over1.drop(columns = [\"fraud\"])\n",
    "y_train_under = fraud_over1[\"fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m log_reg1 \u001b[38;5;241m=\u001b[39m LogisticRegression()\n\u001b[0;32m----> 2\u001b[0m log_reg1\u001b[38;5;241m.\u001b[39mfit(X_train_under, y_train_under)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1246\u001b[0m     )\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
     ]
    }
   ],
   "source": [
    "log_reg1 = LogisticRegression()\n",
    "log_reg1.fit(X_train_under, y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state = 1, sampling_strategy=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud\n",
       "0.0    684596\n",
       "1.0     65404\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm,y_train_sm = sm.fit_resample(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud\n",
       "0.0    684596\n",
       "1.0    684596\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    228001\n",
      "         1.0       0.57      0.95      0.72     21999\n",
      "\n",
      "    accuracy                           0.93    250000\n",
      "   macro avg       0.78      0.94      0.84    250000\n",
      "weighted avg       0.96      0.93      0.94    250000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = log_reg.predict(X_test_scaled)\n",
    "print(classification_report(y_pred = pred, y_true = y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
