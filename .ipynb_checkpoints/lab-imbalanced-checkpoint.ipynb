{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB | Imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**\n",
    "\n",
    "In this challenge, we will be working with Credit Card Fraud dataset.\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\n",
    "\n",
    "Metadata\n",
    "\n",
    "- **distance_from_home:** the distance from home where the transaction happened.\n",
    "- **distance_from_last_transaction:** the distance from last transaction happened.\n",
    "- **ratio_to_median_purchase_price:** Ratio of purchased price transaction to median purchase price.\n",
    "- **repeat_retailer:** Is the transaction happened from same retailer.\n",
    "- **used_chip:** Is the transaction through chip (credit card).\n",
    "- **used_pin_number:** Is the transaction happened by using PIN number.\n",
    "- **online_order:** Is the transaction an online order.\n",
    "- **fraud:** Is the transaction fraudulent. **0=legit** -  **1=fraud**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940              1.0        1.0   \n",
       "1                        1.294219              1.0        0.0   \n",
       "2                        0.427715              1.0        0.0   \n",
       "3                        0.362663              1.0        1.0   \n",
       "4                        2.222767              1.0        1.0   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0              0.0           0.0    0.0  \n",
       "1              0.0           0.0    0.0  \n",
       "2              0.0           1.0    0.0  \n",
       "3              0.0           1.0    0.0  \n",
       "4              0.0           1.0    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = pd.read_csv(\"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/card_transdata.csv\")\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   distance_from_home              1000000 non-null  float64\n",
      " 1   distance_from_last_transaction  1000000 non-null  float64\n",
      " 2   ratio_to_median_purchase_price  1000000 non-null  float64\n",
      " 3   repeat_retailer                 1000000 non-null  float64\n",
      " 4   used_chip                       1000000 non-null  float64\n",
      " 5   used_pin_number                 1000000 non-null  float64\n",
      " 6   online_order                    1000000 non-null  float64\n",
      " 7   fraud                           1000000 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 61.0 MB\n"
     ]
    }
   ],
   "source": [
    "fraud.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1.** What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "- **2.** Train a LogisticRegression.\n",
    "- **3.** Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "- **4.** Run **Oversample** in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model? \n",
    "- **5.** Now, run **Undersample** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "- **6.** Finally, run **SMOTE** in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud\n",
      "0.0    0.912597\n",
      "1.0    0.087403\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#. What is the distribution of our target variable? Can we say we're dealing with an imbalanced dataset?\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "fraud_distribution = fraud['fraud'].value_counts(normalize=True)\n",
    "print(fraud_distribution)\n",
    "\n",
    "#Fraudulent transactions are only 8.74% of the dataset, it is definatelly an imbalanced dataset.\n",
    "#Models trained on imbalanced datasets may have a bias towards the majority class, which in this case is non-fraudulent transactions.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[181291   1228]\n",
      " [  6916  10565]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.98    182519\n",
      "         1.0       0.90      0.60      0.72     17481\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.93      0.80      0.85    200000\n",
      "weighted avg       0.96      0.96      0.96    200000\n",
      "\n",
      "\n",
      "ROC AUC Score:\n",
      "0.9670409810026577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "#2. Train a LogisticRegression.\n",
    "#3. Evaluate your model. Take in consideration class importance, and evaluate it by selection the correct metric.\n",
    "\n",
    "\n",
    "\n",
    "# train and test sets\n",
    "X = fraud.drop(columns=['fraud'])\n",
    "y = fraud['fraud']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train reg. mod\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nROC AUC Score:\")\n",
    "print(roc_auc_score(y_test, y_pred_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#4. Run Oversample in order to balance our target variable and repeat the steps above, now with balanced data. Does it improve the performance of our model?\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_res, y_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Logistic Regression model on the balanced dataset\n",
    "log_reg.fit(X_res, y_res)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_res = log_reg.predict(X_test)\n",
    "y_pred_res_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix (Oversampled):\")\n",
    "print(confusion_matrix(y_test, y_pred_res))\n",
    "print(\"\\nClassification Report (Oversampled):\")\n",
    "print(classification_report(y_test, y_pred_res))\n",
    "print(\"\\nROC AUC Score (Oversampled):\")\n",
    "print(roc_auc_score(y_test, y_pred_res_proba))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Undersampled):\n",
      "[[170386  12133]\n",
      " [   917  16564]]\n",
      "\n",
      "Classification Report (Undersampled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    182519\n",
      "         1.0       0.58      0.95      0.72     17481\n",
      "\n",
      "    accuracy                           0.93    200000\n",
      "   macro avg       0.79      0.94      0.84    200000\n",
      "weighted avg       0.96      0.93      0.94    200000\n",
      "\n",
      "\n",
      "ROC AUC Score (Undersampled):\n",
      "0.9795773854342927\n"
     ]
    }
   ],
   "source": [
    "#5. Now, run Undersample in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train model on the balanced dataset\n",
    "log_reg.fit(X_res, y_res)\n",
    "\n",
    "# test set\n",
    "y_pred_res = log_reg.predict(X_test)\n",
    "y_pred_res_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix (Undersampled):\")\n",
    "print(confusion_matrix(y_test, y_pred_res))\n",
    "print(\"\\nClassification Report (Undersampled):\")\n",
    "print(classification_report(y_test, y_pred_res))\n",
    "print(\"\\nROC AUC Score (Undersampled):\")\n",
    "print(roc_auc_score(y_test, y_pred_res_proba))\n",
    "\n",
    "#Accuracy: The accuracy of the undersampled model is slightly lower (0.93) compared to the original model (0.96). This is expected as undersampling reduces the number of non-fraudulent cases, making the model more balanced but also potentially less accurate overall.\n",
    "\n",
    "#The undersampled model has significantly improved recall for the minority class (fraudulent transactions), which is crucial for identifying fraud cases. However, it comes at the cost of lower precision and overall accuracy. The improved ROC AUC score indicates better performance in distinguishing between fraudulent and non-fraudulent transactions.\n",
    "\n",
    "#In scenarios where identifying fraudulent transactions is critical (even at the cost of more false positives), the undersampled model performs better. However, if the cost of false positives is high, the original model might be preferred.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (SMOTE):\n",
      "[[170500  12019]\n",
      " [   942  16539]]\n",
      "\n",
      "Classification Report (SMOTE):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.93      0.96    182519\n",
      "         1.0       0.58      0.95      0.72     17481\n",
      "\n",
      "    accuracy                           0.94    200000\n",
      "   macro avg       0.79      0.94      0.84    200000\n",
      "weighted avg       0.96      0.94      0.94    200000\n",
      "\n",
      "\n",
      "ROC AUC Score (SMOTE):\n",
      "0.9791832099721023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#6. Finally, run SMOTE in order to balance our target variable and repeat the steps above (1-3), now with balanced data. Does it improve the performance of our model?\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train a Logistic model on the balanced dataset\n",
    "log_reg.fit(X_res, y_res)\n",
    "\n",
    "# test set\n",
    "y_pred_res = log_reg.predict(X_test)\n",
    "y_pred_res_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix (SMOTE):\")\n",
    "print(confusion_matrix(y_test, y_pred_res))\n",
    "print(\"\\nClassification Report (SMOTE):\")\n",
    "print(classification_report(y_test, y_pred_res))\n",
    "print(\"\\nROC AUC Score (SMOTE):\")\n",
    "print(roc_auc_score(y_test, y_pred_res_proba))\n",
    "\n",
    "\n",
    "#Using SMOTE has resulted in a model that balances precision and recall for the fraudulent class better than the original model. While accuracy is slightly lower than the original model, the recall for the fraudulent class is significantly improved. The ROC AUC score indicates that the model with SMOTE performs well in distinguishing between fraudulent and non-fraudulent transactions.\n",
    "\n",
    "#balancing the dataset using SMOTE has led to better performance in terms of recall for the minority class (fraudulent transactions) while maintaining a good overall performance. This makes the SMOTE model a strong candidate when the identification of fraudulent transactions is critical.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
